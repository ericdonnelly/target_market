{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from PIL import ImageFile\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_alternative_validation_split_method(main_dir_path, split=0.2):\n",
    "    \n",
    "    shutil.copytree(main_dir_path, main_dir_path + '_alt')\n",
    "    \n",
    "    main_dir_path = main_dir_path + '_alt'\n",
    "    train_path = main_dir_path + '/train'\n",
    "    validation_path = main_dir_path + '/validate'\n",
    "    \n",
    "    if os.path.isdir(train_path) or os.path.isdir(validation_path):\n",
    "        print('You have already split your training and test data')\n",
    "        \n",
    "    else:\n",
    "        sub_dir_names = os.listdir(main_dir_path)\n",
    "        os.mkdir(train_path)\n",
    "        os.mkdir(validation_path)\n",
    "        for sub_dir_name in sub_dir_names:\n",
    "            name = sub_dir_name.split('_')[0]\n",
    "            os.mkdir(train_path + '/'+ name)\n",
    "            os.mkdir(validation_path + '/'+ name)\n",
    "            images = os.listdir(main_dir_path +'/' + sub_dir_name)\n",
    "            val_n = int(split * len(images))\n",
    "            val_images = images[:val_n]\n",
    "            for i in range(len(val_images)):\n",
    "                for filepath in glob(main_dir_path +'/' + sub_dir_name + '/' + val_images[i]):\n",
    "                    shutil.move(main_dir_path +'/' + sub_dir_name + '/' + val_images[i], validation_path +'/' + name + '/' + val_images[i])\n",
    "            training_images = os.listdir(main_dir_path +'/' + sub_dir_name)\n",
    "            print(f'{name}: {len(images)} total images')\n",
    "            print(f'{name}: {len(training_images)} training images')\n",
    "            print(f'{name}: {val_n} validation images')\n",
    "            print('validation split: ', 100 * round(val_n/(val_n + len(training_images)),2), '%')\n",
    "            print()\n",
    "            for i in range(len(training_images)):\n",
    "                for filepath in glob(main_dir_path +'/' + sub_dir_name + '/' + training_images[i]):\n",
    "                    shutil.move(main_dir_path +'/' + sub_dir_name + '/' + training_images[i], train_path +'/' + name + '/' + training_images[i])\n",
    "        for sub_dir_name in sub_dir_names:\n",
    "            os.rmdir(main_dir_path +'/' + sub_dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'resources/data_for_training_06.zip'\n",
    "\n",
    "zip_ref = zipfile.ZipFile(data, 'r')\n",
    "zip_ref.extractall('resources')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_dir = 'resources/data_for_training_06'\n",
    "\n",
    "# if '.DS_Store/' in os.listdir(main_dir):\n",
    "#    os.remove('.DS_Store/')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brick: 1872 total images\n",
      "brick: 1498 training images\n",
      "brick: 374 validation images\n",
      "validation split:  20.0 %\n",
      "\n",
      "siding: 1529 total images\n",
      "siding: 1224 training images\n",
      "siding: 305 validation images\n",
      "validation split:  20.0 %\n",
      "\n",
      "unknown: 704 total images\n",
      "unknown: 564 training images\n",
      "unknown: 140 validation images\n",
      "validation split:  20.0 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_alternative_validation_split_method(main_dir, split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# ADJUST FILTER?\n",
    "model.add(Conv2D(filters=2, kernel_size=2, padding='same',\n",
    "                 activation='relu', input_shape=(500, 500, 3)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters=4, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Conv2D(filters=8, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=12, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Adding rescale, rotation_range, width_shift_range, height_shift_range,\n",
    "# # shear_range, zoom_range, and horizontal flip to our ImageDataGenerator\n",
    "# train_datagen = ImageDataGenerator(\n",
    "#     rescale=1./255,\n",
    "#     rotation_range=40,\n",
    "#     width_shift_range=0.2,\n",
    "#     height_shift_range=0.2,\n",
    "#     shear_range=0.2,\n",
    "#     zoom_range=0.2,\n",
    "#     horizontal_flip=True,)\n",
    "\n",
    "# # Note that the validation data should not be augmented!\n",
    "# val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# # Flow training images in batches of 32 using train_datagen generator\n",
    "# train_generator = train_datagen.flow_from_directory(\n",
    "#         main_dir + '_alt' + '/train',  # This is the source directory for training images\n",
    "#         target_size=(400, 400),  \n",
    "#         batch_size=20,\n",
    "#         # Since we use binary_crossentropy loss, we need binary labels\n",
    "#         class_mode='categorical')\n",
    "\n",
    "# # Flow validation images in batches of 32 using val_datagen generator\n",
    "# validation_generator = val_datagen.flow_from_directory(\n",
    "#         main_dir + '_alt' + '/validate',\n",
    "#         target_size=(400, 400),\n",
    "#         batch_size=20,\n",
    "#         class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# model.add(Conv2D(filters=4, kernel_size=2, padding='same',\n",
    "#                  activation='relu', input_shape=(400, 400, 3)))\n",
    "# model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "# model.add(Conv2D(filters=8, kernel_size=2, padding='same', activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=2))\n",
    "# model.add(Dropout(0.1))\n",
    "\n",
    "# model.add(Conv2D(filters=12, kernel_size=2, padding='same', activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=2))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(Conv2D(filters=16, kernel_size=2, padding='same', activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=2))\n",
    "# model.add(Dropout(0.3))\n",
    "\n",
    "\n",
    "\n",
    "# model.add(Flatten())\n",
    "\n",
    "# model.add(Dense(256, activation='relu'))\n",
    "\n",
    "# model.add(Dropout(0.4))\n",
    "\n",
    "# model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "# model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = 15\n",
    "\n",
    "# checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.image_classifier.hdf5',\n",
    "#                                verbose=1, save_best_only=True)\n",
    "\n",
    "# history = model.fit(train_tensors, train_targets, validation_data=(valid_tensors, valid_targets),\n",
    "#           epochs=epochs, batch_size=64, callbacks=[checkpointer], verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
